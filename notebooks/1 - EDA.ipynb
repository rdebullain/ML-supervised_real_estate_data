{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The os module has a perfect method to list files in a directory.\n",
    "- Pandas json normalize could work here but is not necessary to convert the JSON data to a dataframe.\n",
    "- You may need a nested for-loop to access each sale!\n",
    "- We've put a lot of time into creating the structure of this repository, and it's a good example for future projects.  In the file functions_variables.py, there is an example function that you can import and use.  If you have any variables, functions or classes that you want to make, they can be put in the functions_variables.py file and imported into a notebook.  Note that only .py files can be imported into a notebook. If you want to import everything from a .py file, you can use the following:\n",
    "```python\n",
    "from functions_variables import *\n",
    "```\n",
    "If you just import functions_variables, then each object from the file will need to be prepended with \"functions_variables\"\\\n",
    "Using this .py file will keep your notebooks very organized and make it easier to reuse code between notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from functions_variables import encode_tags\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_files(directory_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    Process JSON files in the specified directory, normalize the data, and save it to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - directory_path: str, path to the directory containing JSON files.\n",
    "    - output_csv_path: str, path to save the output CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # List all JSON files in the specified directory\n",
    "    files = [f for f in os.listdir(directory_path) if f.endswith('.json')]\n",
    "    print(\"Files in directory:\")\n",
    "    print(files)\n",
    "\n",
    "    # Initialize an empty list to store dataframes\n",
    "    df_list = []\n",
    "\n",
    "    # Iterate over each JSON file in the directory\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        # Open and read the JSON file\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # First level normalization\n",
    "        df = pd.json_normalize(data['data']['results'])\n",
    "        \n",
    "        # Second level normalization\n",
    "        if 'branding' in df.columns:\n",
    "            branding = pd.json_normalize(df['branding'].explode())\n",
    "            branding.columns = [f'branding.{col}' for col in branding.columns]\n",
    "            df = df.drop('branding', axis=1).join(branding)\n",
    "\n",
    "        if 'description' in df.columns:\n",
    "            description = pd.json_normalize(df['description'])\n",
    "            description.columns = [f'description.{col}' for col in description.columns]\n",
    "            df = df.drop('description', axis=1).join(description)\n",
    "\n",
    "        if 'flags' in df.columns:\n",
    "            flags = pd.json_normalize(df['flags'])\n",
    "            flags.columns = [f'flags.{col}' for col in flags.columns]\n",
    "            df = df.drop('flags', axis=1).join(flags)\n",
    "\n",
    "        if 'lead_attributes' in df.columns:\n",
    "            lead_attributes = pd.json_normalize(df['lead_attributes'])\n",
    "            lead_attributes.columns = [f'lead_attributes.{col}' for col in lead_attributes.columns]\n",
    "            df = df.drop('lead_attributes', axis=1).join(lead_attributes)\n",
    "\n",
    "        if 'location.address' in df.columns:\n",
    "            location_address = pd.json_normalize(df['location.address'])\n",
    "            location_address.columns = [f'location.address.{col}' for col in location_address.columns]\n",
    "            df = df.drop('location.address', axis=1).join(location_address)\n",
    "\n",
    "        if 'location.county' in df.columns:\n",
    "            location_county = pd.json_normalize(df['location.county'])\n",
    "            location_county.columns = [f'location.county.{col}' for col in location_county.columns]\n",
    "            df = df.drop('location.county', axis=1).join(location_county)\n",
    "\n",
    "        if 'products' in df.columns:\n",
    "            products = pd.json_normalize(df['products'])\n",
    "            products.columns = [f'products.{col}' for col in products.columns]\n",
    "            df = df.drop('products', axis=1).join(products)\n",
    "\n",
    "        # Third level normalization\n",
    "        if 'location.address.coordinate' in df.columns:\n",
    "            location_coordinates = pd.json_normalize(df['location.address.coordinate'])\n",
    "            location_coordinates.columns = [f'location.address.coordinate.{col}' for col in location_coordinates.columns]\n",
    "            df = df.drop('location.address.coordinate', axis=1).join(location_coordinates)\n",
    "\n",
    "        if 'source.agents' in df.columns:\n",
    "            source_agents = pd.json_normalize(df['source.agents'].explode())\n",
    "            source_agents.columns = [f'source.agents.{col}' for col in source_agents.columns]\n",
    "            df = df.drop('source.agents', axis=1).join(source_agents)\n",
    "            \n",
    "            # Handle duplicate office_name values\n",
    "            if 'source.agents.office_name' in df.columns:\n",
    "                df['source.agents.office_name'] = df['source.agents.office_name'].apply(lambda x: list(set(x)) if isinstance(x, list) else x)\n",
    "\n",
    "        if 'other_listings.rdc' in df.columns:\n",
    "            other_listings_rdc = pd.json_normalize(df['other_listings.rdc'].explode())\n",
    "            other_listings_rdc.columns = [f'other_listings.rdc.{col}' for col in other_listings_rdc.columns]\n",
    "            df = df.drop('other_listings.rdc', axis=1).join(other_listings_rdc)\n",
    "\n",
    "        # Ensure all-bool object columns are cast to bool dtype\n",
    "        for col in df.select_dtypes(include=['object']):\n",
    "            if df[col].dropna().isin([True, False]).all():\n",
    "                df[col] = df[col].astype(bool)\n",
    "        \n",
    "        # Append the dataframe to the list, skipping 'tags' column normalization\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Combine all dataframes\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory:\n",
      "['AK_Juneau_0.json', 'AK_Juneau_1.json', 'AK_Juneau_2.json', 'AK_Juneau_3.json', 'AK_Juneau_4.json', 'AL_Montgomery_0.json', 'AL_Montgomery_1.json', 'AL_Montgomery_2.json', 'AL_Montgomery_3.json', 'AL_Montgomery_4.json', 'AR_LittleRock_0.json', 'AR_LittleRock_1.json', 'AR_LittleRock_2.json', 'AR_LittleRock_3.json', 'AR_LittleRock_4.json', 'AZ_Phoenix_0.json', 'AZ_Phoenix_1.json', 'AZ_Phoenix_2.json', 'AZ_Phoenix_3.json', 'AZ_Phoenix_4.json', 'CA_Sacramento_0.json', 'CA_Sacramento_1.json', 'CA_Sacramento_2.json', 'CA_Sacramento_3.json', 'CA_Sacramento_4.json', 'CO_Denver_0.json', 'CO_Denver_1.json', 'CO_Denver_2.json', 'CO_Denver_3.json', 'CO_Denver_4.json', 'CT_Hartford_0.json', 'CT_Hartford_1.json', 'CT_Hartford_2.json', 'CT_Hartford_3.json', 'CT_Hartford_4.json', 'DE_Dover_0.json', 'DE_Dover_1.json', 'DE_Dover_2.json', 'DE_Dover_3.json', 'DE_Dover_4.json', 'FL_Tallahassee_0.json', 'FL_Tallahassee_1.json', 'FL_Tallahassee_2.json', 'FL_Tallahassee_3.json', 'FL_Tallahassee_4.json', 'GA_Atlanta_0.json', 'GA_Atlanta_1.json', 'GA_Atlanta_2.json', 'GA_Atlanta_3.json', 'GA_Atlanta_4.json', 'HI_Honolulu_0.json', 'HI_Honolulu_1.json', 'HI_Honolulu_2.json', 'HI_Honolulu_3.json', 'HI_Honolulu_4.json', 'IA_DesMoines_0.json', 'IA_DesMoines_1.json', 'IA_DesMoines_2.json', 'IA_DesMoines_3.json', 'IA_DesMoines_4.json', 'ID_Boise_0.json', 'ID_Boise_1.json', 'ID_Boise_2.json', 'ID_Boise_3.json', 'ID_Boise_4.json', 'IL_Springfield_0.json', 'IL_Springfield_1.json', 'IL_Springfield_2.json', 'IL_Springfield_3.json', 'IL_Springfield_4.json', 'IN_Indianapolis_0.json', 'IN_Indianapolis_1.json', 'IN_Indianapolis_2.json', 'IN_Indianapolis_3.json', 'IN_Indianapolis_4.json', 'KS_Topeka_0.json', 'KS_Topeka_1.json', 'KS_Topeka_2.json', 'KS_Topeka_3.json', 'KS_Topeka_4.json', 'KY_Frankfort_0.json', 'KY_Frankfort_1.json', 'KY_Frankfort_2.json', 'KY_Frankfort_3.json', 'KY_Frankfort_4.json', 'LA_BatonRouge_0.json', 'LA_BatonRouge_1.json', 'LA_BatonRouge_2.json', 'LA_BatonRouge_3.json', 'LA_BatonRouge_4.json', 'MA_Boston_0.json', 'MA_Boston_1.json', 'MA_Boston_2.json', 'MA_Boston_3.json', 'MA_Boston_4.json', 'MD_Annapolis_0.json', 'MD_Annapolis_1.json', 'MD_Annapolis_2.json', 'MD_Annapolis_3.json', 'MD_Annapolis_4.json', 'ME_Augusta_0.json', 'ME_Augusta_1.json', 'ME_Augusta_2.json', 'ME_Augusta_3.json', 'ME_Augusta_4.json', 'MI_Lansing_0.json', 'MI_Lansing_1.json', 'MI_Lansing_2.json', 'MI_Lansing_3.json', 'MI_Lansing_4.json', 'MN_St.Paul_0.json', 'MN_St.Paul_1.json', 'MN_St.Paul_2.json', 'MN_St.Paul_3.json', 'MN_St.Paul_4.json', 'MO_JeffersonCity_0.json', 'MO_JeffersonCity_1.json', 'MO_JeffersonCity_2.json', 'MO_JeffersonCity_3.json', 'MO_JeffersonCity_4.json', 'MS_Jackson_0.json', 'MS_Jackson_1.json', 'MS_Jackson_2.json', 'MS_Jackson_3.json', 'MS_Jackson_4.json', 'MT_Helena_0.json', 'MT_Helena_1.json', 'MT_Helena_2.json', 'MT_Helena_3.json', 'MT_Helena_4.json', 'NC_Raleigh_0.json', 'NC_Raleigh_1.json', 'NC_Raleigh_2.json', 'NC_Raleigh_3.json', 'NC_Raleigh_4.json', 'ND_Bismarck_0.json', 'ND_Bismarck_1.json', 'ND_Bismarck_2.json', 'ND_Bismarck_3.json', 'ND_Bismarck_4.json', 'NE_Lincoln_0.json', 'NE_Lincoln_1.json', 'NE_Lincoln_2.json', 'NE_Lincoln_3.json', 'NE_Lincoln_4.json', 'NH_Concord_0.json', 'NH_Concord_1.json', 'NH_Concord_2.json', 'NH_Concord_3.json', 'NH_Concord_4.json', 'NJ_Trenton_0.json', 'NJ_Trenton_1.json', 'NJ_Trenton_2.json', 'NJ_Trenton_3.json', 'NJ_Trenton_4.json', 'NM_SantaFe_0.json', 'NM_SantaFe_1.json', 'NM_SantaFe_2.json', 'NM_SantaFe_3.json', 'NM_SantaFe_4.json', 'NV_CarsonCity_0.json', 'NV_CarsonCity_1.json', 'NV_CarsonCity_2.json', 'NV_CarsonCity_3.json', 'NV_CarsonCity_4.json', 'NY_Albany_0.json', 'NY_Albany_1.json', 'NY_Albany_2.json', 'NY_Albany_3.json', 'NY_Albany_4.json', 'OH_Columbus_0.json', 'OH_Columbus_1.json', 'OH_Columbus_2.json', 'OH_Columbus_3.json', 'OH_Columbus_4.json', 'OK_OklahomaCity_0.json', 'OK_OklahomaCity_1.json', 'OK_OklahomaCity_2.json', 'OK_OklahomaCity_3.json', 'OK_OklahomaCity_4.json', 'OR_Salem_0.json', 'OR_Salem_1.json', 'OR_Salem_2.json', 'OR_Salem_3.json', 'OR_Salem_4.json', 'PA_Harrisburg_0.json', 'PA_Harrisburg_1.json', 'PA_Harrisburg_2.json', 'PA_Harrisburg_3.json', 'PA_Harrisburg_4.json', 'RI_Providence_0.json', 'RI_Providence_1.json', 'RI_Providence_2.json', 'RI_Providence_3.json', 'RI_Providence_4.json', 'SC_Columbia_0.json', 'SC_Columbia_1.json', 'SC_Columbia_2.json', 'SC_Columbia_3.json', 'SC_Columbia_4.json', 'SD_Pierre_0.json', 'SD_Pierre_1.json', 'SD_Pierre_2.json', 'SD_Pierre_3.json', 'SD_Pierre_4.json', 'TN_Nashville_0.json', 'TN_Nashville_1.json', 'TN_Nashville_2.json', 'TN_Nashville_3.json', 'TN_Nashville_4.json', 'TX_Austin_0.json', 'TX_Austin_1.json', 'TX_Austin_2.json', 'TX_Austin_3.json', 'TX_Austin_4.json', 'UT_SaltLakeCity_0.json', 'UT_SaltLakeCity_1.json', 'UT_SaltLakeCity_2.json', 'UT_SaltLakeCity_3.json', 'UT_SaltLakeCity_4.json', 'VA_Richmond_0.json', 'VA_Richmond_1.json', 'VA_Richmond_2.json', 'VA_Richmond_3.json', 'VA_Richmond_4.json', 'VT_Montpelier_0.json', 'VT_Montpelier_1.json', 'VT_Montpelier_2.json', 'VT_Montpelier_3.json', 'VT_Montpelier_4.json', 'WA_Olympia_0.json', 'WA_Olympia_1.json', 'WA_Olympia_2.json', 'WA_Olympia_3.json', 'WA_Olympia_4.json', 'WI_Madison_0.json', 'WI_Madison_1.json', 'WI_Madison_2.json', 'WI_Madison_3.json', 'WI_Madison_4.json', 'WV_Charleston_0.json', 'WV_Charleston_1.json', 'WV_Charleston_2.json', 'WV_Charleston_3.json', 'WV_Charleston_4.json', 'WY_Cheyenne_0.json', 'WY_Cheyenne_1.json', 'WY_Cheyenne_2.json', 'WY_Cheyenne_3.json', 'WY_Cheyenne_4.json']\n",
      "Data saved to e:/Vocational/Lighthouse Labs/Flex Course/Projects/P02_Midterm_Supervised Learning/data_project_midterm/data/processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# example usage\n",
    "directory_path = 'e:/Vocational/Lighthouse Labs/Flex Course/Projects/P02_Midterm_Supervised Learning/data_project_midterm/data'\n",
    "output_csv_path = 'e:/Vocational/Lighthouse Labs/Flex Course/Projects/P02_Midterm_Supervised Learning/data_project_midterm/data/processed_data.csv'\n",
    "process_json_files(directory_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, ensure that you have all sales in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_csv_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is each cell one value, or do some cells have lists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>permalink</th>\n",
       "      <th>status</th>\n",
       "      <th>list_date</th>\n",
       "      <th>open_houses</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>community</th>\n",
       "      <th>virtual_tours</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>price_reduced_amount</th>\n",
       "      <th>matterport</th>\n",
       "      <th>primary_photo.href</th>\n",
       "      <th>source.plan_id</th>\n",
       "      <th>source.spec_id</th>\n",
       "      <th>source.type</th>\n",
       "      <th>description.year_built</th>\n",
       "      <th>description.baths_3qtr</th>\n",
       "      <th>description.sold_date</th>\n",
       "      <th>description.sold_price</th>\n",
       "      <th>description.baths_full</th>\n",
       "      <th>description.name</th>\n",
       "      <th>description.baths_half</th>\n",
       "      <th>description.lot_sqft</th>\n",
       "      <th>description.sqft</th>\n",
       "      <th>description.baths</th>\n",
       "      <th>description.sub_type</th>\n",
       "      <th>description.baths_1qtr</th>\n",
       "      <th>description.garage</th>\n",
       "      <th>description.stories</th>\n",
       "      <th>description.beds</th>\n",
       "      <th>description.type</th>\n",
       "      <th>lead_attributes.show_contact_an_agent</th>\n",
       "      <th>flags.is_new_construction</th>\n",
       "      <th>flags.is_for_rent</th>\n",
       "      <th>flags.is_subdivision</th>\n",
       "      <th>flags.is_contingent</th>\n",
       "      <th>flags.is_price_reduced</th>\n",
       "      <th>flags.is_pending</th>\n",
       "      <th>flags.is_foreclosure</th>\n",
       "      <th>flags.is_plan</th>\n",
       "      <th>flags.is_coming_soon</th>\n",
       "      <th>flags.is_new_listing</th>\n",
       "      <th>products.brand_name</th>\n",
       "      <th>location.address.postal_code</th>\n",
       "      <th>location.address.state</th>\n",
       "      <th>location.address.coordinate.lon</th>\n",
       "      <th>location.address.coordinate.lat</th>\n",
       "      <th>location.address.city</th>\n",
       "      <th>location.address.state_code</th>\n",
       "      <th>location.address.line</th>\n",
       "      <th>location.street_view_url</th>\n",
       "      <th>location.county.fips_code</th>\n",
       "      <th>location.county.name</th>\n",
       "      <th>primary_photo</th>\n",
       "      <th>source</th>\n",
       "      <th>other_listings</th>\n",
       "      <th>branding.name</th>\n",
       "      <th>branding.photo</th>\n",
       "      <th>branding.type</th>\n",
       "      <th>source.agents.office_name</th>\n",
       "      <th>other_listings.rdc.listing_id</th>\n",
       "      <th>other_listings.rdc.listing_key</th>\n",
       "      <th>other_listings.rdc.status</th>\n",
       "      <th>other_listings.rdc.primary</th>\n",
       "      <th>community.advertisers</th>\n",
       "      <th>community.description.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-19T20:52:50Z</td>\n",
       "      <td>['carport', 'community_outdoor_space', 'cul_de...</td>\n",
       "      <td>9453-Herbert-Pl_Juneau_AK_99801_M90744-30767</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-06-29T21:16:25.000000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>554950.0</td>\n",
       "      <td>9.074431e+09</td>\n",
       "      <td>[{'tags': [{'label': 'house_view', 'probabilit...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2957241843</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>https://ap.rdcpix.com/07097d34c98a59ebb7996889...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mls</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-09-18</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10454.0</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>single_family</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>basic_opt_in</td>\n",
       "      <td>99801.0</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>-134.59372</td>\n",
       "      <td>58.36395</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>AK</td>\n",
       "      <td>9453 Herbert Pl</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>False</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EXP Realty LLC - Southeast Alaska</td>\n",
       "      <td>False</td>\n",
       "      <td>Office</td>\n",
       "      <td>EXP Realty LLC - Southeast Alaska</td>\n",
       "      <td>2.957242e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sold</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8477-Thunder-Mountain-Rd_Juneau_AK_99801_M9424...</td>\n",
       "      <td>sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.424984e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99801.0</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>AK</td>\n",
       "      <td>8477 Thunder Mountain Rd</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>False</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Office</td>\n",
       "      <td>Non-Member Office</td>\n",
       "      <td>2.957023e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>off_market</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4515-Glacier-Hwy_Juneau_AK_99801_M94790-68516</td>\n",
       "      <td>sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.479069e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99801.0</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>AK</td>\n",
       "      <td>4515 Glacier Hwy</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>False</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.958935e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sold</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17850-Point-Stephens-Rd_Juneau_AK_99801_M98793...</td>\n",
       "      <td>sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.879332e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99801.0</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>AK</td>\n",
       "      <td>17850 Point Stephens Rd</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>False</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.958935e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sold</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9951-Stephen-Richards-Memorial-Dr_Juneau_AK_99...</td>\n",
       "      <td>sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.521640e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99801.0</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>AK</td>\n",
       "      <td>9951 Stephen Richards Memorial Dr</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>False</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.958925e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sold</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       last_update_date                                               tags  \\\n",
       "0  2023-09-19T20:52:50Z  ['carport', 'community_outdoor_space', 'cul_de...   \n",
       "1                   NaN                                                NaN   \n",
       "2                   NaN                                                NaN   \n",
       "3                   NaN                                                NaN   \n",
       "4                   NaN                                                NaN   \n",
       "\n",
       "                                           permalink status  \\\n",
       "0       9453-Herbert-Pl_Juneau_AK_99801_M90744-30767   sold   \n",
       "1  8477-Thunder-Mountain-Rd_Juneau_AK_99801_M9424...   sold   \n",
       "2      4515-Glacier-Hwy_Juneau_AK_99801_M94790-68516   sold   \n",
       "3  17850-Point-Stephens-Rd_Juneau_AK_99801_M98793...   sold   \n",
       "4  9951-Stephen-Richards-Memorial-Dr_Juneau_AK_99...   sold   \n",
       "\n",
       "                     list_date open_houses list_price   property_id  \\\n",
       "0  2023-06-29T21:16:25.000000Z       False   554950.0  9.074431e+09   \n",
       "1                          NaN       False        NaN  9.424984e+09   \n",
       "2                          NaN       False        NaN  9.479069e+09   \n",
       "3                          NaN       False        NaN  9.879332e+09   \n",
       "4                          NaN       False        NaN  9.521640e+09   \n",
       "\n",
       "                                              photos community virtual_tours  \\\n",
       "0  [{'tags': [{'label': 'house_view', 'probabilit...     False         False   \n",
       "1                                                NaN     False         False   \n",
       "2                                                NaN     False         False   \n",
       "3                                                NaN     False         False   \n",
       "4                                                NaN     False         False   \n",
       "\n",
       "   listing_id price_reduced_amount matterport  \\\n",
       "0  2957241843              45000.0      False   \n",
       "1         NaN                  NaN      False   \n",
       "2         NaN                  NaN      False   \n",
       "3         NaN                  NaN      False   \n",
       "4         NaN                  NaN      False   \n",
       "\n",
       "                                  primary_photo.href source.plan_id  \\\n",
       "0  https://ap.rdcpix.com/07097d34c98a59ebb7996889...            NaN   \n",
       "1                                                NaN            NaN   \n",
       "2                                                NaN            NaN   \n",
       "3                                                NaN            NaN   \n",
       "4                                                NaN            NaN   \n",
       "\n",
       "  source.spec_id source.type description.year_built description.baths_3qtr  \\\n",
       "0            NaN         mls                 1963.0                  False   \n",
       "1            NaN         NaN                    NaN                  False   \n",
       "2            NaN         NaN                    NaN                  False   \n",
       "3            NaN         NaN                    NaN                  False   \n",
       "4            NaN         NaN                    NaN                  False   \n",
       "\n",
       "  description.sold_date description.sold_price description.baths_full  \\\n",
       "0            2023-09-18                  False                    2.0   \n",
       "1            2023-08-22                  False                    NaN   \n",
       "2            2023-08-22                  False                    NaN   \n",
       "3            2023-08-21                  False                    NaN   \n",
       "4            2023-08-21                  False                    NaN   \n",
       "\n",
       "  description.name description.baths_half description.lot_sqft  \\\n",
       "0            False                  False              10454.0   \n",
       "1            False                  False                  NaN   \n",
       "2            False                  False                  NaN   \n",
       "3            False                  False                  NaN   \n",
       "4            False                  False                  NaN   \n",
       "\n",
       "  description.sqft  description.baths description.sub_type  \\\n",
       "0           1821.0                2.0                  NaN   \n",
       "1              NaN                NaN                  NaN   \n",
       "2              NaN                NaN                  NaN   \n",
       "3              NaN                NaN                  NaN   \n",
       "4              NaN                NaN                  NaN   \n",
       "\n",
       "  description.baths_1qtr description.garage description.stories  \\\n",
       "0                  False                1.0                 NaN   \n",
       "1                  False                NaN                 NaN   \n",
       "2                  False                NaN                 NaN   \n",
       "3                  False                NaN                 NaN   \n",
       "4                  False                NaN                 NaN   \n",
       "\n",
       "  description.beds description.type lead_attributes.show_contact_an_agent  \\\n",
       "0              3.0    single_family                                  True   \n",
       "1              NaN              NaN                                  True   \n",
       "2              NaN              NaN                                  True   \n",
       "3              NaN              NaN                                  True   \n",
       "4              NaN              NaN                                  True   \n",
       "\n",
       "  flags.is_new_construction flags.is_for_rent flags.is_subdivision  \\\n",
       "0                     False             False                False   \n",
       "1                     False             False                False   \n",
       "2                     False             False                False   \n",
       "3                     False             False                False   \n",
       "4                     False             False                False   \n",
       "\n",
       "  flags.is_contingent flags.is_price_reduced flags.is_pending  \\\n",
       "0               False                  False            False   \n",
       "1               False                  False            False   \n",
       "2               False                  False            False   \n",
       "3               False                  False            False   \n",
       "4               False                  False            False   \n",
       "\n",
       "  flags.is_foreclosure flags.is_plan flags.is_coming_soon  \\\n",
       "0                False         False                False   \n",
       "1                False         False                False   \n",
       "2                False         False                False   \n",
       "3                False         False                False   \n",
       "4                False         False                False   \n",
       "\n",
       "  flags.is_new_listing products.brand_name  location.address.postal_code  \\\n",
       "0                False        basic_opt_in                       99801.0   \n",
       "1                False                 NaN                       99801.0   \n",
       "2                False                 NaN                       99801.0   \n",
       "3                False                 NaN                       99801.0   \n",
       "4                False                 NaN                       99801.0   \n",
       "\n",
       "  location.address.state  location.address.coordinate.lon  \\\n",
       "0                 Alaska                       -134.59372   \n",
       "1                 Alaska                              NaN   \n",
       "2                 Alaska                              NaN   \n",
       "3                 Alaska                              NaN   \n",
       "4                 Alaska                              NaN   \n",
       "\n",
       "   location.address.coordinate.lat location.address.city  \\\n",
       "0                         58.36395                Juneau   \n",
       "1                              NaN                Juneau   \n",
       "2                              NaN                Juneau   \n",
       "3                              NaN                Juneau   \n",
       "4                              NaN                Juneau   \n",
       "\n",
       "  location.address.state_code              location.address.line  \\\n",
       "0                          AK                    9453 Herbert Pl   \n",
       "1                          AK           8477 Thunder Mountain Rd   \n",
       "2                          AK                   4515 Glacier Hwy   \n",
       "3                          AK            17850 Point Stephens Rd   \n",
       "4                          AK  9951 Stephen Richards Memorial Dr   \n",
       "\n",
       "                            location.street_view_url  \\\n",
       "0  https://maps.googleapis.com/maps/api/streetvie...   \n",
       "1  https://maps.googleapis.com/maps/api/streetvie...   \n",
       "2  https://maps.googleapis.com/maps/api/streetvie...   \n",
       "3  https://maps.googleapis.com/maps/api/streetvie...   \n",
       "4  https://maps.googleapis.com/maps/api/streetvie...   \n",
       "\n",
       "  location.county.fips_code location.county.name primary_photo source  \\\n",
       "0                     False               Juneau           NaN    NaN   \n",
       "1                     False               Juneau           NaN    NaN   \n",
       "2                     False               Juneau           NaN    NaN   \n",
       "3                     False               Juneau           NaN    NaN   \n",
       "4                     False               Juneau           NaN    NaN   \n",
       "\n",
       "  other_listings                      branding.name branding.photo  \\\n",
       "0            NaN  EXP Realty LLC - Southeast Alaska          False   \n",
       "1            NaN                                NaN          False   \n",
       "2            NaN                                NaN          False   \n",
       "3            NaN                                NaN          False   \n",
       "4            NaN                                NaN          False   \n",
       "\n",
       "  branding.type          source.agents.office_name  \\\n",
       "0        Office  EXP Realty LLC - Southeast Alaska   \n",
       "1        Office                  Non-Member Office   \n",
       "2        Office                                NaN   \n",
       "3        Office                                NaN   \n",
       "4        Office                                NaN   \n",
       "\n",
       "   other_listings.rdc.listing_id other_listings.rdc.listing_key  \\\n",
       "0                   2.957242e+09                            NaN   \n",
       "1                   2.957023e+09                            NaN   \n",
       "2                   2.958935e+09                            NaN   \n",
       "3                   2.958935e+09                            NaN   \n",
       "4                   2.958925e+09                            NaN   \n",
       "\n",
       "  other_listings.rdc.status other_listings.rdc.primary community.advertisers  \\\n",
       "0                      sold                       True                   NaN   \n",
       "1                off_market                      False                   NaN   \n",
       "2                      sold                      False                   NaN   \n",
       "3                      sold                      False                   NaN   \n",
       "4                      sold                      False                   NaN   \n",
       "\n",
       "  community.description.name  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are the data types of each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns and their data types:\n",
      "last_update_date                          object\n",
      "tags                                      object\n",
      "permalink                                 object\n",
      "status                                    object\n",
      "list_date                                 object\n",
      "open_houses                               object\n",
      "list_price                                object\n",
      "property_id                              float64\n",
      "photos                                    object\n",
      "community                                 object\n",
      "virtual_tours                             object\n",
      "listing_id                                object\n",
      "price_reduced_amount                      object\n",
      "matterport                                object\n",
      "primary_photo.href                        object\n",
      "source.plan_id                            object\n",
      "source.spec_id                            object\n",
      "source.type                               object\n",
      "description.year_built                    object\n",
      "description.baths_3qtr                    object\n",
      "description.sold_date                     object\n",
      "description.sold_price                    object\n",
      "description.baths_full                    object\n",
      "description.name                          object\n",
      "description.baths_half                    object\n",
      "description.lot_sqft                      object\n",
      "description.sqft                          object\n",
      "description.baths                        float64\n",
      "description.sub_type                      object\n",
      "description.baths_1qtr                    object\n",
      "description.garage                        object\n",
      "description.stories                       object\n",
      "description.beds                          object\n",
      "description.type                          object\n",
      "lead_attributes.show_contact_an_agent     object\n",
      "flags.is_new_construction                 object\n",
      "flags.is_for_rent                         object\n",
      "flags.is_subdivision                      object\n",
      "flags.is_contingent                       object\n",
      "flags.is_price_reduced                    object\n",
      "flags.is_pending                          object\n",
      "flags.is_foreclosure                      object\n",
      "flags.is_plan                             object\n",
      "flags.is_coming_soon                      object\n",
      "flags.is_new_listing                      object\n",
      "products.brand_name                       object\n",
      "location.address.postal_code             float64\n",
      "location.address.state                    object\n",
      "location.address.coordinate.lon          float64\n",
      "location.address.coordinate.lat          float64\n",
      "location.address.city                     object\n",
      "location.address.state_code               object\n",
      "location.address.line                     object\n",
      "location.street_view_url                  object\n",
      "location.county.fips_code                 object\n",
      "location.county.name                      object\n",
      "primary_photo                             object\n",
      "source                                    object\n",
      "other_listings                            object\n",
      "branding.name                             object\n",
      "branding.photo                            object\n",
      "branding.type                             object\n",
      "source.agents.office_name                 object\n",
      "other_listings.rdc.listing_id            float64\n",
      "other_listings.rdc.listing_key            object\n",
      "other_listings.rdc.status                 object\n",
      "other_listings.rdc.primary                object\n",
      "community.advertisers                     object\n",
      "community.description.name                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# display all columns and their data types\n",
    "print(\"Columns and their data types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some sales may not actually include the sale price. These rows should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped: 37\n"
     ]
    }
   ],
   "source": [
    "# number of rows before dropping\n",
    "rows_before = len(df)\n",
    "\n",
    "# drop rows without 'description.sold_price' (target variable)\n",
    "df = df.dropna(subset=['description.sold_price'])\n",
    "\n",
    "# number of rows after dropping\n",
    "rows_after = len(df)\n",
    "\n",
    "# calculate the number of rows dropped\n",
    "rows_dropped = rows_before - rows_after\n",
    "\n",
    "# print the number of rows dropped\n",
    "print(f\"Number of rows dropped: {rows_dropped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are a lot of None values.  Should these be dropped or replaced with something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in each column:\n",
      "last_update_date                          0.416973\n",
      "tags                                      6.217807\n",
      "permalink                                 0.000000\n",
      "status                                    0.000000\n",
      "list_date                                 4.881040\n",
      "open_houses                               0.000000\n",
      "list_price                                5.261221\n",
      "property_id                               0.000000\n",
      "photos                                    8.891342\n",
      "community                                 2.575423\n",
      "virtual_tours                            74.540103\n",
      "listing_id                                4.881040\n",
      "price_reduced_amount                     68.297768\n",
      "matterport                                0.000000\n",
      "primary_photo.href                        9.271523\n",
      "source.plan_id                           17.525141\n",
      "source.spec_id                           17.525141\n",
      "source.type                               4.991415\n",
      "description.year_built                   10.326220\n",
      "description.baths_3qtr                   13.662006\n",
      "description.sold_date                     0.000000\n",
      "description.sold_price                    0.000000\n",
      "description.baths_full                   10.363012\n",
      "description.name                          0.000000\n",
      "description.baths_half                   68.960020\n",
      "description.lot_sqft                     14.152563\n",
      "description.sqft                         10.154525\n",
      "description.baths                         2.195242\n",
      "description.sub_type                     70.063772\n",
      "description.baths_1qtr                    0.000000\n",
      "description.garage                       43.549178\n",
      "description.stories                      23.154280\n",
      "description.beds                          7.996076\n",
      "description.type                          0.416973\n",
      "lead_attributes.show_contact_an_agent     0.000000\n",
      "flags.is_new_construction                 0.000000\n",
      "flags.is_for_rent                         0.000000\n",
      "flags.is_subdivision                      0.000000\n",
      "flags.is_contingent                       0.000000\n",
      "flags.is_price_reduced                    0.000000\n",
      "flags.is_pending                          0.000000\n",
      "flags.is_foreclosure                      0.000000\n",
      "flags.is_plan                             0.000000\n",
      "flags.is_coming_soon                      0.000000\n",
      "flags.is_new_listing                      0.000000\n",
      "products.brand_name                       5.960265\n",
      "location.address.postal_code              0.000000\n",
      "location.address.state                    0.000000\n",
      "location.address.coordinate.lon           3.065980\n",
      "location.address.coordinate.lat           3.065980\n",
      "location.address.city                     0.061320\n",
      "location.address.state_code               0.000000\n",
      "location.address.line                     0.183959\n",
      "location.street_view_url                  0.000000\n",
      "location.county.fips_code                 6.622517\n",
      "location.county.name                      0.122639\n",
      "primary_photo                            99.619818\n",
      "source                                   99.889625\n",
      "other_listings                           99.889625\n",
      "branding.name                             5.212166\n",
      "branding.photo                           63.306353\n",
      "branding.type                             0.000000\n",
      "source.agents.office_name                81.763552\n",
      "other_listings.rdc.listing_id             1.103753\n",
      "other_listings.rdc.listing_key           15.011038\n",
      "other_listings.rdc.status                 1.103753\n",
      "other_listings.rdc.primary                2.820701\n",
      "community.advertisers                    99.938680\n",
      "community.description.name               99.938680\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check the percentage of missing values in each column\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "print(\"Percentage of missing values in each column:\")\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: Index(['virtual_tours', 'price_reduced_amount', 'description.baths_half',\n",
      "       'description.sub_type', 'primary_photo', 'source', 'other_listings',\n",
      "       'branding.photo', 'source.agents.office_name', 'community.advertisers',\n",
      "       'community.description.name'],\n",
      "      dtype='object')\n",
      "Remaining columns after dropping:\n",
      "Index(['last_update_date', 'tags', 'permalink', 'status', 'list_date',\n",
      "       'open_houses', 'list_price', 'property_id', 'photos', 'community',\n",
      "       'listing_id', 'matterport', 'primary_photo.href', 'source.plan_id',\n",
      "       'source.spec_id', 'source.type', 'description.year_built',\n",
      "       'description.baths_3qtr', 'description.sold_date',\n",
      "       'description.sold_price', 'description.baths_full', 'description.name',\n",
      "       'description.lot_sqft', 'description.sqft', 'description.baths',\n",
      "       'description.baths_1qtr', 'description.garage', 'description.stories',\n",
      "       'description.beds', 'description.type',\n",
      "       'lead_attributes.show_contact_an_agent', 'flags.is_new_construction',\n",
      "       'flags.is_for_rent', 'flags.is_subdivision', 'flags.is_contingent',\n",
      "       'flags.is_price_reduced', 'flags.is_pending', 'flags.is_foreclosure',\n",
      "       'flags.is_plan', 'flags.is_coming_soon', 'flags.is_new_listing',\n",
      "       'products.brand_name', 'location.address.postal_code',\n",
      "       'location.address.state', 'location.address.coordinate.lon',\n",
      "       'location.address.coordinate.lat', 'location.address.city',\n",
      "       'location.address.state_code', 'location.address.line',\n",
      "       'location.street_view_url', 'location.county.fips_code',\n",
      "       'location.county.name', 'branding.name', 'branding.type',\n",
      "       'other_listings.rdc.listing_id', 'other_listings.rdc.listing_key',\n",
      "       'other_listings.rdc.status', 'other_listings.rdc.primary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# calculate the percentage of missing values in each column\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "\n",
    "# define a threshold for dropping columns (e.g., rule of thumb: more than 50% missing values)\n",
    "threshold = 50\n",
    "\n",
    "# identify columns to drop based on the threshold\n",
    "columns_to_drop = missing_percentage[missing_percentage > threshold].index\n",
    "\n",
    "# drop the identified columns from the DataFrame\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# print the dropped columns\n",
    "print(f\"Dropped columns: {columns_to_drop}\")\n",
    "\n",
    "# display the remaining columns\n",
    "print(\"Remaining columns after dropping:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of irrelevant columns to drop\n",
    "columns_to_drop = ['last_update_date', 'permalink', 'status', 'open_houses', 'list_price', 'property_id', 'photos', 'community', \n",
    "                   'listing_id', 'matterport', 'primary_photo.href', 'source.plan_id', 'source.spec_id', 'source.type', \n",
    "                   'location.street_view_url', 'matterport', 'description.name', 'description.baths_1qtr', \n",
    "                   'lead_attributes.show_contact_an_agent', 'flags.is_new_construction', 'flags.is_for_rent', 'flags.is_subdivision', \n",
    "                   'flags.is_contingent', 'flags.is_pending', 'flags.is_plan', 'flags.is_coming_soon', 'flags.is_new_listing', \n",
    "                   'products.brand_name', 'location.address.postal_code', 'location.address.coordinate.lon', 'location.address.coordinate.lat', \n",
    "                   'location.address.state_code', 'location.address.line', 'location.street_view_url', 'location.county.fips_code', 'branding.type', \n",
    "                   'other_listings.rdc.listing_id', 'other_listings.rdc.listing_key', 'other_listings.rdc.status', 'other_listings.rdc.primary']\n",
    "\n",
    "# drop the specified columns\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags                                   object\n",
      "list_date                 datetime64[ns, UTC]\n",
      "description.year_built                  Int64\n",
      "description.baths_3qtr                  Int64\n",
      "description.sold_date          datetime64[ns]\n",
      "description.sold_price                float64\n",
      "description.baths_full                  Int64\n",
      "description.lot_sqft                    Int64\n",
      "description.sqft                        Int64\n",
      "description.baths                     float64\n",
      "description.garage                      Int64\n",
      "description.stories                     Int64\n",
      "description.beds                        Int64\n",
      "description.type                       object\n",
      "flags.is_price_reduced                   bool\n",
      "flags.is_foreclosure                     bool\n",
      "location.address.state                 object\n",
      "location.address.city                  object\n",
      "location.county.name                   object\n",
      "branding.name                          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert tags to lists\n",
    "df['tags'] = df['tags'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Convert date columns to datetime\n",
    "df['list_date'] = pd.to_datetime(df['list_date'], errors='coerce')\n",
    "df['description.sold_date'] = pd.to_datetime(df['description.sold_date'], errors='coerce')\n",
    "\n",
    "# Convert year built to integer\n",
    "df['description.year_built'] = pd.to_numeric(df['description.year_built'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convert baths_3qtr, baths_full, and other bath-related columns to numeric\n",
    "df['description.baths_3qtr'] = pd.to_numeric(df['description.baths_3qtr'], errors='coerce').astype('Int64')\n",
    "df['description.baths_full'] = pd.to_numeric(df['description.baths_full'], errors='coerce').astype('Int64')\n",
    "df['description.baths'] = pd.to_numeric(df['description.baths'], errors='coerce').astype('float')\n",
    "df['description.garage'] = pd.to_numeric(df['description.garage'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convert sold_price, lot_sqft, and sqft to numeric\n",
    "df['description.sold_price'] = pd.to_numeric(df['description.sold_price'], errors='coerce').astype('float')\n",
    "df['description.lot_sqft'] = pd.to_numeric(df['description.lot_sqft'], errors='coerce').astype('Int64')\n",
    "df['description.sqft'] = pd.to_numeric(df['description.sqft'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convert stories and beds to integer\n",
    "df['description.stories'] = pd.to_numeric(df['description.stories'], errors='coerce').astype('Int64')\n",
    "df['description.beds'] = pd.to_numeric(df['description.beds'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convert type to string\n",
    "df['description.type'] = df['description.type'].astype(str)\n",
    "\n",
    "# Convert flags to boolean\n",
    "df['flags.is_price_reduced'] = df['flags.is_price_reduced'].astype(bool)\n",
    "df['flags.is_foreclosure'] = df['flags.is_foreclosure'].astype(bool)\n",
    "\n",
    "# Convert location and branding columns to string\n",
    "df['location.address.state'] = df['location.address.state'].astype(str)\n",
    "df['location.address.city'] = df['location.address.city'].astype(str)\n",
    "df['location.county.name'] = df['location.county.name'].astype(str)\n",
    "df['branding.name'] = df['branding.name'].astype(str)\n",
    "\n",
    "# Display the DataFrame with updated types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some sales don't include the property type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[180], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m categorical_cols \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      3\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m df[categorical_cols] \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mfit_transform(df[categorical_cols])\n",
      "File \u001b[1;32mc:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:427\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_fit(\n\u001b[0;32m    424\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values, fill_value\n\u001b[0;32m    425\u001b[0m     )\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_fit(\n\u001b[0;32m    428\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values, fill_value\n\u001b[0;32m    429\u001b[0m     )\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:523\u001b[0m, in \u001b[0;36mSimpleImputer._dense_fit\u001b[1;34m(self, X, strategy, missing_values, fill_value)\u001b[0m\n\u001b[0;32m    521\u001b[0m             most_frequent[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 523\u001b[0m             most_frequent[i] \u001b[38;5;241m=\u001b[39m _most_frequent(row, np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m most_frequent\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# Constant\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:44\u001b[0m, in \u001b[0;36m_most_frequent\u001b[1;34m(array, extra_value, n_repeat)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;66;03m# scipy.stats.mode is slow with object dtype array.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;66;03m# Python Counter is more efficient\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m         counter \u001b[38;5;241m=\u001b[39m Counter(array)\n\u001b[0;32m     45\u001b[0m         most_frequent_count \u001b[38;5;241m=\u001b[39m counter\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;66;03m# tie breaking similarly to scipy.stats.mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\16476\\anaconda3\\Lib\\collections\\__init__.py:599\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;124;03mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;124;03mof elements to their counts.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m \n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(iterable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\16476\\anaconda3\\Lib\\collections\\__init__.py:690\u001b[0m, in \u001b[0;36mCounter.update\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    688\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(iterable)\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 690\u001b[0m         _count_elements(\u001b[38;5;28mself\u001b[39m, iterable)\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# impute missing values for categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_cols] = imputer.fit_transform(df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values for numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df[numerical_cols] = imputer.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to replace False with 0\n",
    "def replace_false_with_zero(value):\n",
    "    if value is False:\n",
    "        return 0\n",
    "    return value\n",
    "\n",
    "# Apply the function to the 'description.baths_3qtr' column\n",
    "if 'description.baths_3qtr' in df.columns:\n",
    "    df['description.baths_3qtr'] = df['description.baths_3qtr'].apply(replace_false_with_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in each column:\n",
      "tags                      0.000000\n",
      "list_date                 0.000000\n",
      "description.year_built    0.000000\n",
      "description.baths_3qtr    0.000000\n",
      "description.sold_date     0.000000\n",
      "description.sold_price    0.000000\n",
      "description.baths_full    0.000000\n",
      "description.lot_sqft      0.000000\n",
      "description.sqft          0.000000\n",
      "description.baths         2.195242\n",
      "description.garage        0.000000\n",
      "description.stories       0.000000\n",
      "description.beds          0.000000\n",
      "description.type          0.000000\n",
      "flags.is_price_reduced    0.000000\n",
      "flags.is_foreclosure      0.000000\n",
      "location.address.state    0.000000\n",
      "location.address.city     0.000000\n",
      "location.county.name      0.000000\n",
      "branding.name             0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check the percentage of missing values in each column\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "print(\"Percentage of missing values in each column:\")\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineer new column called 'days_on_market'\n",
    "\n",
    "# Ensure the date columns are in the same format and timezone-naive\n",
    "df['description.sold_date'] = pd.to_datetime(df['description.sold_date'], errors='coerce').dt.tz_localize(None)\n",
    "df['list_date'] = pd.to_datetime(df['list_date'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "# Calculate the days on market\n",
    "df['days_on_market'] = (df['description.sold_date'] - df['list_date']).dt.days\n",
    "\n",
    "# Drop the original date columns\n",
    "df = df.drop(['description.sold_date', 'list_date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the fact that with tags, there are a lot of categorical variables.\n",
    "- Maybe the \"tags\" will help create some features.\n",
    "- Perhaps we can get rid of tags that have a low frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineer a new column called 'number_of_attributes' from the 'tags' column\n",
    "\n",
    "# Convert string representation of lists into actual lists and handle booleans\n",
    "def convert_to_list(val):\n",
    "    if isinstance(val, bool):\n",
    "        return []  # Treat boolean as an empty list\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "df['tags'] = df['tags'].apply(convert_to_list)\n",
    "\n",
    "# Count the number of values in each list and create a new column\n",
    "df['number_of_attributes'] = df['tags'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Drop the original 'tags' column\n",
    "df = df.drop('tags', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'number_of_attributes': 32\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique values in the 'number_of_attributes' column\n",
    "num_unique_values = df['number_of_attributes'].nunique()\n",
    "print(f\"Number of unique values in 'number_of_attributes': {num_unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cap outliers at a specified percentile\n",
    "def cap_outliers(df, cols, lower_percentile=0.05, upper_percentile=0.95):\n",
    "    for col in cols:\n",
    "        lower_bound = df[col].quantile(lower_percentile)\n",
    "        upper_bound = df[col].quantile(upper_percentile)\n",
    "        df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    return df\n",
    "\n",
    "# identify all numerical columns to cap outliers\n",
    "numerical_cols_to_cap = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# cap outliers in these numerical columns\n",
    "df = cap_outliers(df, numerical_cols_to_cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many columns would we have if we OHE tags, city and state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the specified columns\n",
    "columns_to_encode = [\n",
    "    'location.address.city', 'location.address.state', \n",
    "    'location.county.name', 'branding.name', \n",
    "    'flags.is_price_reduced', 'flags.is_foreclosure'\n",
    "]\n",
    "\n",
    "# One-hot encoding for the specified columns\n",
    "df = pd.get_dummies(df, columns=columns_to_encode, prefix=columns_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to e:/Vocational/Lighthouse Labs/Flex Course/Projects/P02_Midterm_Supervised Learning/data_project_midterm/data/processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the combined DataFrame to a CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sales will vary drastically between cities and states.  Is there a way to keep information about which city it is without OHE such as using central tendency?\n",
    "- Could we label encode or ordinal encode?  Yes, but this may have undesirable effects, giving nominal data ordinal values.\n",
    "- If you replace cities or states with numerical values, make sure that the data is split so that we don't leak data into the training selection. This is a great time to train test split. Compute on the training data, and join these values to the test data\n",
    "- Drop columns that aren't needed.\n",
    "- Don't keep the list price because it will be too close to the sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the DataFrame into training (70%) and test (30%) sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the split data to CSV files if needed\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "test_df.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STRETCH**\n",
    "\n",
    "- You're not limited to just using the data provided to you. Think/ do some research about other features that might be useful to predict housing prices. \n",
    "- Can you import and join this data? Make sure you do any necessary preprocessing and make sure it is joined correctly.\n",
    "- Example suggestion: could mortgage interest rates in the year of the listing affect the price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import, join and preprocess new data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember all of the EDA that you've been learning about?  Now is a perfect time for it!\n",
    "- Look at distributions of numerical variables to see the shape of the data and detect outliers.\n",
    "- Scatterplots of a numerical variable and the target go a long way to show correlations.\n",
    "- A heatmap will help detect highly correlated features, and we don't want these.\n",
    "- Is there any overlap in any of the features? (redundant information, like number of this or that room...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('path_to_your_data/processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Summary Statistics\n",
    "def summary_statistics(df):\n",
    "    print(\"Summary Statistics:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nData Types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "summary_statistics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check for Missing Values\n",
    "def missing_values(df):\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Distributions of Numerical Variables\n",
    "def plot_distributions(df):\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numerical_cols:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(df[col], kde=True)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.show()\n",
    "\n",
    "plot_distributions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Scatterplots for Numerical Variables and Target\n",
    "def scatterplots(df, target_col):\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    numerical_cols = [col for col in numerical_cols if col != target_col]\n",
    "    for col in numerical_cols:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(x=df[col], y=df[target_col])\n",
    "        plt.title(f'Scatterplot of {col} vs {target_col}')\n",
    "        plt.show()\n",
    "\n",
    "target_col = 'sold_price'\n",
    "scatterplots(df, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Correlation Heatmap\n",
    "def correlation_heatmap(df):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    corr_matrix = df.corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.show()\n",
    "\n",
    "correlation_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Redundant Features\n",
    "def check_redundant_features(df):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    redundant_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.8)]\n",
    "    print(\"Redundant Features:\")\n",
    "    print(redundant_features)\n",
    "\n",
    "check_redundant_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Boxplots to Identify Outliers\n",
    "def plot_boxplots(df):\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numerical_cols:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x=df[col])\n",
    "        plt.title(f'Boxplot of {col}')\n",
    "        plt.show()\n",
    "\n",
    "plot_boxplots(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is a great time to scale the data and save it once it's preprocessed.\n",
    "- You can save it in your data folder, but you may want to make a new `processed/` subfolder to keep it organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
