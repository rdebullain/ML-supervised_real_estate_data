{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Set display options for easier DataFrame visualization\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_files(directory_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    Process JSON files in the specified directory, normalize the data, and save it to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - directory_path: str, path to the directory containing JSON files.\n",
    "    - output_csv_path: str, path to save the output CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # List all JSON files in the specified directory\n",
    "    files = [f for f in os.listdir(directory_path) if f.endswith('.json')]\n",
    "    print(\"Files in directory:\")\n",
    "    print(files)\n",
    "\n",
    "    # Initialize an empty list to store dataframes\n",
    "    df_list = []\n",
    "\n",
    "    # Iterate over each JSON file in the directory\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        # Open and read the JSON file\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # First level normalization\n",
    "        df = pd.json_normalize(data['data']['results'])\n",
    "        \n",
    "        # Second level normalization\n",
    "        if 'branding' in df.columns:\n",
    "            branding = pd.json_normalize(df['branding'].explode())\n",
    "            branding.columns = [f'branding.{col}' for col in branding.columns]\n",
    "            df = df.drop('branding', axis=1).join(branding)\n",
    "\n",
    "        if 'description' in df.columns:\n",
    "            description = pd.json_normalize(df['description'])\n",
    "            description.columns = [f'description.{col}' for col in description.columns]\n",
    "            df = df.drop('description', axis=1).join(description)\n",
    "\n",
    "        if 'flags' in df.columns:\n",
    "            flags = pd.json_normalize(df['flags'])\n",
    "            flags.columns = [f'flags.{col}' for col in flags.columns]\n",
    "            df = df.drop('flags', axis=1).join(flags)\n",
    "\n",
    "        if 'lead_attributes' in df.columns:\n",
    "            lead_attributes = pd.json_normalize(df['lead_attributes'])\n",
    "            lead_attributes.columns = [f'lead_attributes.{col}' for col in lead_attributes.columns]\n",
    "            df = df.drop('lead_attributes', axis=1).join(lead_attributes)\n",
    "\n",
    "        if 'location.address' in df.columns:\n",
    "            location_address = pd.json_normalize(df['location.address'])\n",
    "            location_address.columns = [f'location.address.{col}' for col in location_address.columns]\n",
    "            df = df.drop('location.address', axis=1).join(location_address)\n",
    "\n",
    "        if 'location.county' in df.columns:\n",
    "            location_county = pd.json_normalize(df['location.county'])\n",
    "            location_county.columns = [f'location.county.{col}' for col in location_county.columns]\n",
    "            df = df.drop('location.county', axis=1).join(location_county)\n",
    "\n",
    "        if 'products' in df.columns:\n",
    "            products = pd.json_normalize(df['products'])\n",
    "            products.columns = [f'products.{col}' for col in products.columns]\n",
    "            df = df.drop('products', axis=1).join(products)\n",
    "\n",
    "        # Third level normalization\n",
    "        if 'location.address.coordinate' in df.columns:\n",
    "            location_coordinates = pd.json_normalize(df['location.address.coordinate'])\n",
    "            location_coordinates.columns = [f'location.address.coordinate.{col}' for col in location_coordinates.columns]\n",
    "            df = df.drop('location.address.coordinate', axis=1).join(location_coordinates)\n",
    "\n",
    "        if 'source.agents' in df.columns:\n",
    "            source_agents = pd.json_normalize(df['source.agents'].explode())\n",
    "            source_agents.columns = [f'source.agents.{col}' for col in source_agents.columns]\n",
    "            df = df.drop('source.agents', axis=1).join(source_agents)\n",
    "            \n",
    "            # Handle duplicate office_name values\n",
    "            if 'source.agents.office_name' in df.columns:\n",
    "                df['source.agents.office_name'] = df['source.agents.office_name'].apply(lambda x: list(set(x)) if isinstance(x, list) else x)\n",
    "\n",
    "        if 'other_listings.rdc' in df.columns:\n",
    "            other_listings_rdc = pd.json_normalize(df['other_listings.rdc'].explode())\n",
    "            other_listings_rdc.columns = [f'other_listings.rdc.{col}' for col in other_listings_rdc.columns]\n",
    "            df = df.drop('other_listings.rdc', axis=1).join(other_listings_rdc)\n",
    "\n",
    "        # Ensure all-bool object columns are cast to bool dtype\n",
    "        for col in df.select_dtypes(include=['object']):\n",
    "            if df[col].dropna().isin([True, False]).all():\n",
    "                df[col] = df[col].astype(bool)\n",
    "        \n",
    "        # Append the dataframe to the list, skipping 'tags' column normalization\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Combine all dataframes\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory:\n",
      "['AK_Juneau_0.json', 'AK_Juneau_1.json', 'AK_Juneau_2.json', 'AK_Juneau_3.json', 'AK_Juneau_4.json', 'AL_Montgomery_0.json', 'AL_Montgomery_1.json', 'AL_Montgomery_2.json', 'AL_Montgomery_3.json', 'AL_Montgomery_4.json', 'AR_LittleRock_0.json', 'AR_LittleRock_1.json', 'AR_LittleRock_2.json', 'AR_LittleRock_3.json', 'AR_LittleRock_4.json', 'AZ_Phoenix_0.json', 'AZ_Phoenix_1.json', 'AZ_Phoenix_2.json', 'AZ_Phoenix_3.json', 'AZ_Phoenix_4.json', 'CA_Sacramento_0.json', 'CA_Sacramento_1.json', 'CA_Sacramento_2.json', 'CA_Sacramento_3.json', 'CA_Sacramento_4.json', 'CO_Denver_0.json', 'CO_Denver_1.json', 'CO_Denver_2.json', 'CO_Denver_3.json', 'CO_Denver_4.json', 'CT_Hartford_0.json', 'CT_Hartford_1.json', 'CT_Hartford_2.json', 'CT_Hartford_3.json', 'CT_Hartford_4.json', 'DE_Dover_0.json', 'DE_Dover_1.json', 'DE_Dover_2.json', 'DE_Dover_3.json', 'DE_Dover_4.json', 'FL_Tallahassee_0.json', 'FL_Tallahassee_1.json', 'FL_Tallahassee_2.json', 'FL_Tallahassee_3.json', 'FL_Tallahassee_4.json', 'GA_Atlanta_0.json', 'GA_Atlanta_1.json', 'GA_Atlanta_2.json', 'GA_Atlanta_3.json', 'GA_Atlanta_4.json', 'HI_Honolulu_0.json', 'HI_Honolulu_1.json', 'HI_Honolulu_2.json', 'HI_Honolulu_3.json', 'HI_Honolulu_4.json', 'IA_DesMoines_0.json', 'IA_DesMoines_1.json', 'IA_DesMoines_2.json', 'IA_DesMoines_3.json', 'IA_DesMoines_4.json', 'ID_Boise_0.json', 'ID_Boise_1.json', 'ID_Boise_2.json', 'ID_Boise_3.json', 'ID_Boise_4.json', 'IL_Springfield_0.json', 'IL_Springfield_1.json', 'IL_Springfield_2.json', 'IL_Springfield_3.json', 'IL_Springfield_4.json', 'IN_Indianapolis_0.json', 'IN_Indianapolis_1.json', 'IN_Indianapolis_2.json', 'IN_Indianapolis_3.json', 'IN_Indianapolis_4.json', 'KS_Topeka_0.json', 'KS_Topeka_1.json', 'KS_Topeka_2.json', 'KS_Topeka_3.json', 'KS_Topeka_4.json', 'KY_Frankfort_0.json', 'KY_Frankfort_1.json', 'KY_Frankfort_2.json', 'KY_Frankfort_3.json', 'KY_Frankfort_4.json', 'LA_BatonRouge_0.json', 'LA_BatonRouge_1.json', 'LA_BatonRouge_2.json', 'LA_BatonRouge_3.json', 'LA_BatonRouge_4.json', 'MA_Boston_0.json', 'MA_Boston_1.json', 'MA_Boston_2.json', 'MA_Boston_3.json', 'MA_Boston_4.json', 'MD_Annapolis_0.json', 'MD_Annapolis_1.json', 'MD_Annapolis_2.json', 'MD_Annapolis_3.json', 'MD_Annapolis_4.json', 'ME_Augusta_0.json', 'ME_Augusta_1.json', 'ME_Augusta_2.json', 'ME_Augusta_3.json', 'ME_Augusta_4.json', 'MI_Lansing_0.json', 'MI_Lansing_1.json', 'MI_Lansing_2.json', 'MI_Lansing_3.json', 'MI_Lansing_4.json', 'MN_St.Paul_0.json', 'MN_St.Paul_1.json', 'MN_St.Paul_2.json', 'MN_St.Paul_3.json', 'MN_St.Paul_4.json', 'MO_JeffersonCity_0.json', 'MO_JeffersonCity_1.json', 'MO_JeffersonCity_2.json', 'MO_JeffersonCity_3.json', 'MO_JeffersonCity_4.json', 'MS_Jackson_0.json', 'MS_Jackson_1.json', 'MS_Jackson_2.json', 'MS_Jackson_3.json', 'MS_Jackson_4.json', 'MT_Helena_0.json', 'MT_Helena_1.json', 'MT_Helena_2.json', 'MT_Helena_3.json', 'MT_Helena_4.json', 'NC_Raleigh_0.json', 'NC_Raleigh_1.json', 'NC_Raleigh_2.json', 'NC_Raleigh_3.json', 'NC_Raleigh_4.json', 'ND_Bismarck_0.json', 'ND_Bismarck_1.json', 'ND_Bismarck_2.json', 'ND_Bismarck_3.json', 'ND_Bismarck_4.json', 'NE_Lincoln_0.json', 'NE_Lincoln_1.json', 'NE_Lincoln_2.json', 'NE_Lincoln_3.json', 'NE_Lincoln_4.json', 'NH_Concord_0.json', 'NH_Concord_1.json', 'NH_Concord_2.json', 'NH_Concord_3.json', 'NH_Concord_4.json', 'NJ_Trenton_0.json', 'NJ_Trenton_1.json', 'NJ_Trenton_2.json', 'NJ_Trenton_3.json', 'NJ_Trenton_4.json', 'NM_SantaFe_0.json', 'NM_SantaFe_1.json', 'NM_SantaFe_2.json', 'NM_SantaFe_3.json', 'NM_SantaFe_4.json', 'NV_CarsonCity_0.json', 'NV_CarsonCity_1.json', 'NV_CarsonCity_2.json', 'NV_CarsonCity_3.json', 'NV_CarsonCity_4.json', 'NY_Albany_0.json', 'NY_Albany_1.json', 'NY_Albany_2.json', 'NY_Albany_3.json', 'NY_Albany_4.json', 'OH_Columbus_0.json', 'OH_Columbus_1.json', 'OH_Columbus_2.json', 'OH_Columbus_3.json', 'OH_Columbus_4.json', 'OK_OklahomaCity_0.json', 'OK_OklahomaCity_1.json', 'OK_OklahomaCity_2.json', 'OK_OklahomaCity_3.json', 'OK_OklahomaCity_4.json', 'OR_Salem_0.json', 'OR_Salem_1.json', 'OR_Salem_2.json', 'OR_Salem_3.json', 'OR_Salem_4.json', 'PA_Harrisburg_0.json', 'PA_Harrisburg_1.json', 'PA_Harrisburg_2.json', 'PA_Harrisburg_3.json', 'PA_Harrisburg_4.json', 'RI_Providence_0.json', 'RI_Providence_1.json', 'RI_Providence_2.json', 'RI_Providence_3.json', 'RI_Providence_4.json', 'SC_Columbia_0.json', 'SC_Columbia_1.json', 'SC_Columbia_2.json', 'SC_Columbia_3.json', 'SC_Columbia_4.json', 'SD_Pierre_0.json', 'SD_Pierre_1.json', 'SD_Pierre_2.json', 'SD_Pierre_3.json', 'SD_Pierre_4.json', 'TN_Nashville_0.json', 'TN_Nashville_1.json', 'TN_Nashville_2.json', 'TN_Nashville_3.json', 'TN_Nashville_4.json', 'TX_Austin_0.json', 'TX_Austin_1.json', 'TX_Austin_2.json', 'TX_Austin_3.json', 'TX_Austin_4.json', 'UT_SaltLakeCity_0.json', 'UT_SaltLakeCity_1.json', 'UT_SaltLakeCity_2.json', 'UT_SaltLakeCity_3.json', 'UT_SaltLakeCity_4.json', 'VA_Richmond_0.json', 'VA_Richmond_1.json', 'VA_Richmond_2.json', 'VA_Richmond_3.json', 'VA_Richmond_4.json', 'VT_Montpelier_0.json', 'VT_Montpelier_1.json', 'VT_Montpelier_2.json', 'VT_Montpelier_3.json', 'VT_Montpelier_4.json', 'WA_Olympia_0.json', 'WA_Olympia_1.json', 'WA_Olympia_2.json', 'WA_Olympia_3.json', 'WA_Olympia_4.json', 'WI_Madison_0.json', 'WI_Madison_1.json', 'WI_Madison_2.json', 'WI_Madison_3.json', 'WI_Madison_4.json', 'WV_Charleston_0.json', 'WV_Charleston_1.json', 'WV_Charleston_2.json', 'WV_Charleston_3.json', 'WV_Charleston_4.json', 'WY_Cheyenne_0.json', 'WY_Cheyenne_1.json', 'WY_Cheyenne_2.json', 'WY_Cheyenne_3.json', 'WY_Cheyenne_4.json']\n",
      "Data saved to C:\\Users\\16476\\Downloads\\ML-supervised_real_estate_data\\data\\processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# example usage\n",
    "directory_path = r'C:\\Users\\16476\\Downloads\\ML-supervised_real_estate_data\\data'\n",
    "output_csv_path = r'C:\\Users\\16476\\Downloads\\ML-supervised_real_estate_data\\data\\processed_data.csv'\n",
    "process_json_files(directory_path, output_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the_one",
   "language": "python",
   "name": "the_one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
